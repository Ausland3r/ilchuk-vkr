\chapter{Сравнение моделей классификации для разных проектов}\label{appendix2-MikTeX-TexStudio}   

\begin{table}[H]
	\centering
	\caption{Сравнение моделей классификации на проекте Pacan4ik/tinkoff-course-spring2023}
	\label{tab:metrics_comparison_small_extended}
	\resizebox{\textwidth}{!}{
		\begin{tabular}{|l|c c c c|}
			\hline
			\textbf{Модель} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-score} & \textbf{ROC-AUC} \\
			\hline
			LogisticRegression & 0.600 & 1.000 & 0.750 & 0.990 \\
			RandomForest       & 0.800 & 0.667 & 0.727 & 0.979 \\
			ExtraTrees         & 0.800 & 0.667 & 0.727 & 0.984 \\
			GradientBoosting   & 1.000 & 0.833 & 0.909 & 0.995 \\
			AdaBoost           & 1.000 & 0.833 & 0.909 & 0.979 \\
			XGBoost            & 0.800 & 0.667 & 0.727 & 0.979 \\
			LightGBM           & 0.800 & 0.667 & 0.727 & 0.958 \\
			CatBoost           & 0.833 & 0.833 & 0.833 & 0.990 \\
			SVM                & 0.833 & 0.833 & 0.833 & 0.990 \\
			DeepForest         & 0.833 & 0.833 & 0.833 & 0.990 \\
			\hline
		\end{tabular}
	}
\end{table}

\begin{table}[H]
	\centering
	\caption{Сравнение моделей классификации на проекте jup-ag/pyth-crosschain}
	\label{tab:metrics_comparison_large_extended}
	\resizebox{\textwidth}{!}{
		\begin{tabular}{|l|c c c c|}
			\hline
			\textbf{Модель} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-score} & \textbf{ROC-AUC} \\
			\hline
			LogisticRegression & 0.696 & 0.941 & 0.800 & 0.996 \\
			RandomForest       & 0.917 & 0.647 & 0.759 & 0.995 \\
			ExtraTrees         & 0.933 & 0.824 & 0.875 & 0.998 \\
			GradientBoosting   & 0.933 & 0.824 & 0.875 & 0.933 \\
			AdaBoost           & 0.875 & 0.824 & 0.848 & 0.952 \\
			XGBoost            & 0.867 & 0.765 & 0.812 & 0.962 \\
			LightGBM           & 0.818 & 0.529 & 0.643 & 0.946 \\
			CatBoost           & 0.867 & 0.765 & 0.812 & 0.994 \\
			SVM                & 0.938 & 0.882 & 0.909 & 0.999 \\
			DeepForest         & 0.842 & 0.941 & 0.889 & 0.996 \\
			\hline
		\end{tabular}
	}
\end{table}

\begin{table}[H]
	\centering
	\caption{Сравнение моделей классификации на проекте Pacan4ik/tf-idf}
	\label{tab:metrics_comparison_tfidf}
	\resizebox{\textwidth}{!}{
		\begin{tabular}{|l|c c c c|}
			\hline
			\textbf{Модель} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-score} & \textbf{ROC-AUC} \\
			\hline
			LogisticRegression & 0.852 & 0.880 & 0.866 & 0.925 \\
			RandomForest       & 0.810 & 0.760 & 0.784 & 0.890 \\
			ExtraTrees         & 0.820 & 0.780 & 0.799 & 0.905 \\
			GradientBoosting   & 0.780 & 0.740 & 0.759 & 0.885 \\
			AdaBoost           & 0.750 & 0.700 & 0.724 & 0.865 \\
			XGBoost            & 0.830 & 0.790 & 0.810 & 0.910 \\
			LightGBM           & 0.795 & 0.735 & 0.764 & 0.880 \\
			CatBoost           & 0.840 & 0.800 & 0.820 & 0.920 \\
			SVM                & 0.880 & 0.850 & 0.865 & 0.950 \\
			DeepForest         & 0.810 & 0.770 & 0.789 & 0.890 \\
			\hline
		\end{tabular}
	}
\end{table}

\begin{table}[H]
	\centering
	\caption{Сравнение моделей классификации на проекте Ausland3r/NTO2024-2025}
	\label{tab:metrics_comparison_nto}
	\resizebox{\textwidth}{!}{
		\begin{tabular}{|l|c c c c|}
			\hline
			\textbf{Модель} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-score} & \textbf{ROC-AUC} \\
			\hline
			LogisticRegression & 0.667 & 1.000 & 0.800 & 0.917 \\
			RandomForest       & 1.000 & 0.500 & 0.667 & 0.958 \\
			ExtraTrees         & 1.000 & 0.500 & 0.667 & 0.958 \\
			GradientBoosting   & 0.000 & 0.000 & 0.000 & 0.688 \\
			AdaBoost           & 0.000 & 0.000 & 0.000 & 0.917 \\
			XGBoost            & 0.400 & 1.000 & 0.571 & 1.000 \\
			LightGBM           & 1.000 & 1.000 & 1.000 & 1.000 \\
			CatBoost           & 1.000 & 0.500 & 0.667 & 1.000 \\
			SVM                & 0.667 & 1.000 & 0.800 & 0.958 \\
			DeepForest         & 1.000 & 0.500 & 0.667 & 0.958 \\
			\hline
		\end{tabular}
	}
\end{table}

\begin{table}[H]
	\centering
	\caption{Сравнение моделей классификации на проекте Ausland3r/scherBook}
	\label{tab:metrics_comparison_scherbook}
	\resizebox{\textwidth}{!}{
		\begin{tabular}{|l|c c c c|}
			\hline
			\textbf{Модель} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-score} & \textbf{ROC-AUC} \\
			\hline
			LogisticRegression & 0.800 & 0.833 & 0.816 & 0.900 \\
			RandomForest       & 0.750 & 0.667 & 0.706 & 0.880 \\
			ExtraTrees         & 0.770 & 0.700 & 0.734 & 0.890 \\
			GradientBoosting   & 0.720 & 0.600 & 0.656 & 0.850 \\
			AdaBoost           & 0.700 & 0.583 & 0.636 & 0.870 \\
			XGBoost            & 0.820 & 0.833 & 0.826 & 0.920 \\
			LightGBM           & 0.780 & 0.667 & 0.718 & 0.880 \\
			CatBoost           & 0.800 & 0.750 & 0.774 & 0.910 \\
			SVM                & 0.810 & 0.800 & 0.805 & 0.915 \\
			DeepForest         & 0.760 & 0.700 & 0.729 & 0.900 \\
			\hline
		\end{tabular}
	}
\end{table}

\begin{table}[H]
	\centering
	\caption{Сравнение моделей классификации на проекте Ausland3r/Tq}
	\label{tab:metrics_comparison_tq}
	\resizebox{\textwidth}{!}{
		\begin{tabular}{|l|c c c c|}
			\hline
			\textbf{Модель} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-score} & \textbf{ROC-AUC} \\
			\hline
			LogisticRegression & 0.750 & 0.800 & 0.774 & 0.920 \\
			RandomForest       & 0.700 & 0.650 & 0.674 & 0.880 \\
			ExtraTrees         & 0.710 & 0.660 & 0.684 & 0.890 \\
			GradientBoosting   & 0.680 & 0.600 & 0.638 & 0.900 \\
			AdaBoost           & 0.600 & 0.550 & 0.574 & 0.880 \\
			XGBoost            & 0.780 & 0.720 & 0.749 & 0.910 \\
			LightGBM           & 0.700 & 0.650 & 0.674 & 0.880 \\
			CatBoost           & 0.760 & 0.700 & 0.729 & 0.900 \\
			SVM                & 0.800 & 0.750 & 0.774 & 0.930 \\
			DeepForest         & 0.720 & 0.680 & 0.699 & 0.910 \\
			\hline
		\end{tabular}
	}
\end{table}

\begin{table}[H]
	\centering
	\caption{Сравнение моделей классификации на проекте urlagushka/polytech-labs}
	\label{tab:metrics_comparison_polytech}
	\resizebox{\textwidth}{!}{
		\begin{tabular}{|l|c c c c|}
			\hline
			\textbf{Модель} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-score} & \textbf{ROC-AUC} \\
			\hline
			LogisticRegression & 0.950 & 0.900 & 0.924 & 0.970 \\
			RandomForest       & 0.850 & 0.800 & 0.824 & 0.950 \\
			ExtraTrees         & 0.870 & 0.820 & 0.844 & 0.960 \\
			GradientBoosting   & 0.800 & 0.750 & 0.774 & 0.930 \\
			AdaBoost           & 0.780 & 0.700 & 0.738 & 0.940 \\
			XGBoost            & 0.820 & 0.780 & 0.799 & 0.920 \\
			LightGBM           & 0.800 & 0.750 & 0.774 & 0.945 \\
			CatBoost           & 0.880 & 0.800 & 0.838 & 0.970 \\
			SVM                & 0.900 & 0.880 & 0.890 & 0.980 \\
			DeepForest         & 0.840 & 0.880 & 0.860 & 0.970 \\
			\hline
		\end{tabular}
	}
\end{table}

\begin{table}[H]
	\centering
	\caption{Сравнение моделей классификации на проекте urlagushka/h8-pipeline}
	\label{tab:metrics_comparison_h8pipeline}
	\resizebox{\textwidth}{!}{
		\begin{tabular}{|l|c c c c|}
			\hline
			\textbf{Модель} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-score} & \textbf{ROC-AUC} \\
			\hline
			LogisticRegression & 0.820 & 0.750 & 0.783 & 0.910 \\
			RandomForest       & 0.800 & 0.700 & 0.746 & 0.900 \\
			ExtraTrees         & 0.810 & 0.720 & 0.764 & 0.905 \\
			GradientBoosting   & 0.780 & 0.650 & 0.709 & 0.880 \\
			AdaBoost           & 0.760 & 0.630 & 0.689 & 0.885 \\
			XGBoost            & 0.790 & 0.680 & 0.732 & 0.895 \\
			LightGBM           & 0.770 & 0.660 & 0.710 & 0.890 \\
			CatBoost           & 0.800 & 0.720 & 0.758 & 0.915 \\
			SVM                & 0.830 & 0.770 & 0.799 & 0.920 \\
			DeepForest         & 0.820 & 0.740 & 0.778 & 0.915 \\
			\hline
		\end{tabular}
	}
\end{table}
