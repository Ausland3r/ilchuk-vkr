\chapter{Разработка метода, алгоритма, модели исследования} \label{ch2}

\section{Обоснование выбора метода} \label{ch2:method_selection}

В данной главе рассматриваются основные методы и алгоритмы, используемые для анализа данных из репозиториев программного кода. Выбор методов обоснован на основе современных исследований и их практической применимости в задачах анализа коммитов.

\section{Формализация задачи} \label{ch2:problem_formulation}

Основная цель исследования заключается в автоматическом анализе истории коммитов в репозиториях GitHub и выявлении потенциальных аномалий с последующей генерацией корректирующих действий (CAPA). 

Формально, каждый коммит \( c_i \) представляется вектором признаков:
\begin{equation}
	c_i = \{a_i, d_i, t_i, f_i, \tau_i\},
\end{equation}
где:
\begin{itemize}
	\item \( a_i \) --- количество добавленных строк кода,
	\item \( d_i \) --- количество удаленных строк кода,
	\item \( t_i \) --- общее число изменений (сумма добавленных и удаленных строк),
	\item \( f_i \) --- количество измененных файлов,
	\item \( \tau_i \) --- время с момента последнего коммита.
\end{itemize}

\section{Выбор алгоритмов анализа} \label{ch2:algorithm_selection}

Для обработки данных применяются следующие алгоритмы:

\subsection{Метод кластеризации KMeans}
Метод KMeans используется для установления пороговых значений на основе характеристик коммитов. Кластеризация выполняется по признакам \( a, d, t, f, \tau \), что позволяет разделить коммиты на нормальные и потенциально аномальные.

\begin{algorithm}
	\SetAlgoLined
	\KwData{Набор данных коммитов \( C \)}
	\KwResult{Разделение на два кластера: нормальные и аномальные коммиты}
	1. Инициализировать KMeans с параметром \( k=2 \)
	
	2. Применить алгоритм к данным \( C \)
	
	3. Определить центры кластеров \( \mu_1, \mu_2 \)
	
	4. Рассчитать пороговые значения как среднее между центрами
	
	5. Отнести каждый коммит \( c_i \) к соответствующему кластеру
	
%	\caption{Алгоритм кластеризации KMeans}
%	\label{alg:KMeans}
\end{algorithm}

\subsection{Обучение моделей машинного обучения}

Для классификации коммитов в дальнейшем используются два алгоритма:

\begin{itemize}
	\item \textbf{Случайный лес (Random Forest)} --- ансамблевый метод на основе деревьев решений, обеспечивающий высокую точность и устойчивость к шуму.
	\item \textbf{Наивный байесовский классификатор (Naive Bayes)} --- простая вероятностная модель, используемая для базовой оценки данных.
\end{itemize}

Эксперименты показали, что случайный лес демонстрирует более высокую точность (1.0), в то время как наивный Байес достигает точности 0.8.

\section{Глубокий лес (Deep Forest) для предсказания CAPA} \label{ch2:deep_forest}

Для повышения точности классификации была внедрена модель глубокого леса (Cascade Forest). Из-за несовместимости библиотеки deep-forest с Python 3.12 была создана виртуальная среда на Python 3.9.

\begin{algorithm}
	\SetAlgoLined
	\KwData{Набор данных коммитов \( C \)}
	\KwResult{Предсказанные корректирующие действия CAPA}
	1. Разделить данные на тренировочный и тестовый наборы.
	
	2. Обучить модель глубокого леса на тренировочных данных.
	
	3. Оценить точность модели на тестовом наборе.
	
	4. Применить модель к новым данным для предсказания корректирующих действий.
	
%	\caption{Алгоритм глубокого леса}
%	\label{alg:DeepForest}
\end{algorithm}

\section{Заключение} \label{ch2:conclusion}

В данной главе был рассмотрен выбор методов и алгоритмов для анализа коммитов в репозиториях GitHub. Использование метода кластеризации KMeans позволило определить пороговые значения, а применение случайного леса и глубокого леса обеспечило высокую точность предсказаний. Внедрение модели глубокого леса позволило более точно выявлять сложные зависимости в данных и автоматически формировать корректирующие рекомендации.
