\chapter{Обзор источников по предметной области} \label{ch1}

\section{Современные исследования в области анализа данных из репозиториев кода} \label{ch1:sec1}

Современные исследования в области анализа данных из репозиториев кода сосредоточены на автоматизации процессов контроля качества и выявления отклонений на основе методов машинного обучения. Эти подходы позволяют не только выявлять проблемы, но и предотвращать их за счёт своевременных корректирующих действий.

Одной из ключевых задач является анализ коммитов, который рассматривается как источник ценной информации о процессе разработки. Коммиты содержат метрики, такие как количество добавленных и удалённых строк кода, изменённые файлы и временные интервалы между изменениями. Эти данные используются для анализа отклонений от нормального процесса разработки.

Использование метрик позволяет объективно оценить состояние проекта и выявить аномалии в процессе разработки. Наиболее часто используемые метрики включают:
\begin{itemize}
	\item \textbf{Количество добавленных строк кода}: может указывать на крупные изменения или добавление новой функциональности.
	\item \textbf{Количество удалённых строк кода}: часто связано с рефакторингом или устранением избыточного кода.
	\item \textbf{Общее количество изменений}: помогает определить интенсивность работы над проектом.
	\item \textbf{Временные интервалы между коммитами}: являются индикатором ритма работы команды.
\end{itemize}

Эти метрики формируют основу для дальнейшего анализа и автоматической классификации действий разработчиков.

\section{Выявление аномалий и использование паттернов} \label{ch1:sec2}

Исследования показывают, что анализ временных рядов метрик позволяет выявлять повторяющиеся паттерны, связанные с аномалиями. Z-нормализованное евклидово расстояние применяется для измерения схожести между временными рядами, где каждый временной ряд предварительно нормализуется путём вычитания среднего значения и деления на стандартное отклонение. Это делает ряды сопоставимыми независимо от их масштаба. Этот метод позволяет выявить закономерности в изменениях метрик и сопоставить их с характерными действиями разработчиков. Анализ делится на три основных этапа:
\begin{enumerate}
	\item Построение временных рядов на основе ключевых метрик.
	\item Поиск паттернов с использованием алгоритмов кластеризации.
	\item Связь обнаруженных паттернов с корректирующими и предупреждающими действиями (CAPA).
\end{enumerate}

\begin{table}[htbp]
	\centering
	\caption{Примеры паттернов аномалий и их интерпретация}
	\label{tab:patterns}
	\resizebox{\textwidth}{!}{%
		\begin{tabular}{|l|l|l|}
			\hline
			\textbf{Тип паттерна} & \textbf{Возможные причины} & \textbf{Рекомендуемые действия} \\
			\hline
			Резкий рост добавления строк & Добавление новой функциональности & Проведение ревизии кода \\
			\hline
			Частые изменения в одном файле & Проблемы с архитектурой & Разделение задачи на более мелкие части \\
			\hline
			Длительные задержки между коммитами & Потеря фокуса команды & Уточнение приоритетов и планов \\
			\hline
	\end{tabular}}
\end{table}

\section{Разновидности методов машинного обучения} \label{ch1:sec3}

Современные алгоритмы машинного обучения используются для автоматизации анализа данных, так как они позволяют справляться с большими объёмами информации, высокой вариативностью и сложными взаимосвязями между метриками. В контексте анализа данных из репозиториев кода, выбор алгоритмов обусловлен их способностью выявлять закономерности в многомерных временных рядах, обеспечивать интерпретируемость данных, учитывать особенности категориальных и числовых данных. К часто используемым моделям относится:
\begin{itemize}
	\item \textbf{Random Forest} – обеспечивает высокую точность (83\%) и интерпретируемость.
	\item \textbf{XGBoost} – оптимизирован для больших данных, скорость обучения выше (82\%).
	\item \textbf{CatBoost} – стабильно работает с категориальными данными (81\%).
	\item \textbf{Deep Forest} – каскадная структура деревьев решений, эффективна для небольших проектов.
\end{itemize}

\section{Подбор инструментальных средств} \label{ch1:sec4}

Разработка аналитической системы требует использования широкого спектра технических и инструментальных средств, которые обеспечивают поддержку на всех этапах разработки: от обработки данных до визуализации результатов. В данной главе представлен детальный анализ инструментальных средств, критерии их выбора и обоснование принятия решений. Такой подход позволяет выбрать оптимальные технологии, соответствующие целям проекта и обеспечивающие его успешную реализацию.

\subsection{Основной язык программирования}
Для выполнения задач проекта был выбран Python. Выбор языка обоснован анализом следующих критериев:
\begin{itemize}
	\item \textbf{Поддержка библиотек и инструментов}: Наличие развитой экосистемы для анализа данных, машинного обучения и визуализации.
	\item \textbf{Простота и скорость разработки}: Интуитивно понятный синтаксис, упрощающий реализацию сложных алгоритмов.
	\item \textbf{Производительность}: Достаточна для выполнения задач проекта при использовании оптимизированных библиотек.
	\item \textbf{Совместимость}: Возможность интеграции с различными инструментами и системами.
\end{itemize}

\begin{table}[htbp]
	\centering
	\caption{Сравнение языков программирования}
	\label{tab:languages}
	\begin{tabular}{|l|c|c|c|}
		\hline
		\textbf{Критерий} & \textbf{Python} & \textbf{R} & \textbf{C++} \\
		\hline
		Поддержка библиотек & Отличная & Хорошая & Отличная \\
		Простота разработки & Высокая & Средняя & Низкая \\
		Производительность & Средняя & Низкая & Высокая \\
		Совместимость & Отличная & Средняя & Хорошая \\
		\hline
	\end{tabular}
\end{table}

Вывод: Python оказался оптимальным выбором благодаря универсальности, простоте и обширной поддержке библиотек. В отличие от R, Python лучше подходит для машинного обучения, а по сравнению с C++ обеспечивает более быстрый цикл разработки.

\subsection{Библиотеки для анализа и машинного обучения}
Для обработки данных и построения моделей машинного обучения в проекте используются инструменты, которые обеспечивают эффективность, простоту использования и соответствие требованиям задач. Основные выбранные библиотеки и модели:
\begin{itemize}
	\item \textbf{Pandas}: Инструмент для работы с табличными данными, включающий фильтрацию, трансформацию, агрегацию и анализ.
	\item \textbf{Scikit-learn}: Универсальная библиотека для задач классического машинного обучения, включая классификацию и кластеризацию.
	\item \textbf{Deep Forest}: Каскадная структура деревьев решений, подходящая для небольших объёмов данных с высокой интерпретируемостью.
\end{itemize}

\begin{table}[htbp]
	\centering
	\caption{Сравнение моделей машинного обучения}
	\label{tab:ml_models}
	\resizebox{\textwidth}{!}{%
		\begin{tabular}{|l|c|c|c|c|}
			\hline
			\textbf{Критерий} & \textbf{Random Forest} & \textbf{XGBoost} & \textbf{CatBoost} & \textbf{Deep Forest} \\
			\hline
			Область применения & Универсальный & Большие данные & Категориальные данные & Малые и средние данные \\
			Производительность & Высокая & Высокая (GPU) & Высокая & Умеренная \\
			Интерпретируемость & Высокая & Средняя & Средняя & Высокая \\
			Работа с зависимостями & Простые связи & Сложные связи & Ограниченные связи & Глубокие взаимосвязи \\
			Простота настройки & Простая & Сложная & Сложная & Простая \\
			\hline
	\end{tabular}}
\end{table}

Выбор в пользу Deep Forest обусловлен его высокой интерпретируемостью и способностью выявлять сложные зависимости в данных.

\subsection{Средства визуализации}
Для представления данных и взаимодействия с пользователями были рассмотрены несколько инструментов визуализации.

\begin{table}[htbp]
	\centering
	\caption{Сравнение инструментов визуализации}
	\label{tab:visualization}
	\begin{tabular}{|l|c|c|c|}
		\hline
		\textbf{Критерий} & \textbf{Plotly} & \textbf{Matplotlib} & \textbf{Seaborn} \\
		\hline
		Интерактивность & Высокая & Низкая & Низкая \\
		Простота интеграции & Отличная & Средняя & Средняя \\
		Поддержка сложных графиков & Отличная & Хорошая & Средняя \\
		\hline
	\end{tabular}
\end{table}

Выбран Plotly и Dash благодаря их интерактивности и возможности создания дашбордов.

\subsection{Среда разработки}
Для удобства работы над проектом была выбрана среда PyCharm.

\begin{table}[htbp]
	\centering
	\caption{Сравнение сред разработки}
	\label{tab:ide}
	\begin{tabular}{|l|c|c|c|}
		\hline
		\textbf{Критерий} & \textbf{PyCharm} & \textbf{VS Code} & \textbf{Jupyter Notebook} \\
		\hline
		Отладка & Отличная & Хорошая & Ограниченная \\
		Управление зависимостями & Простое & Требует расширений & Не поддерживается \\
		\hline
	\end{tabular}
\end{table}

\subsection{Методы кластеризации и анализа данных}
Для анализа данных выбраны методы кластеризации, такие как KMeans.

\begin{table}[htbp]
	\centering
	\caption{Сравнение алгоритмов кластеризации}
	\label{tab:clustering}
	\resizebox{\textwidth}{!}{%
		\begin{tabular}{|l|c|c|c|}
			\hline
			\textbf{Критерий} & \textbf{KMeans} & \textbf{DBSCAN} & \textbf{Иерархическая кластеризация} \\
			\hline
			Производительность & Высокая & Средняя & Низкая \\
			\hline
			Простота реализации & Простая & Средняя & Сложная \\
			\hline
			Число кластеров & Задаётся заранее & Определяется динамически & Определяется визуально \\
			\hline
	\end{tabular}}
\end{table}

\section{Формулирование цели, задач и гипотез} \label{ch1:sec5}

Исходя из обзора предметной области и выбранных инструментальных средств, сформулируем цель, задачи и гипотезы для разработки системы автоматического анализа данных из репозиториев GitHub.

\textbf{Цель}: Создание системы автоматического извлечения и анализа данных коммитов из репозиториев GitHub с использованием методов кластеризации и машинного обучения для выявления корректирующих и предупреждающих действий (CAPA) и визуализации результатов анализа через интерактивный дашборд.

\textbf{Задачи}:
\begin{itemize}
	\item Изучить потребности пользователей в автоматическом анализе данных репозиториев кода.
	\item Рассмотреть существующие методы и подходы для анализа коммитов, включая методы кластеризации и машинного обучения.
	\item Сформулировать ограничения и требования к системе для повышения её функциональности и точности.
	\item Разработать архитектуру системы, включающую автоматическое извлечение данных, их анализ и визуализацию.
	\item Внедрить алгоритмы кластеризации (например, k-средние) для группировки данных коммитов.
	\item Применить алгоритмы машинного обучения (случайные леса, глубокие леса) для классификации коммитов и выявления CAPA.
	\item Разработать и интегрировать визуализацию результатов анализа с использованием Plotly и Dash.
	\item Автоматизировать создание отчетов и pull request'ов с рекомендациями для GitHub.
	\item Протестировать систему, оценить её эффективность и точность работы.
\end{itemize}

\section{Выводы} \label{ch1:conclusion}

Обзор методов и инструментов анализа показал, что современные подходы эффективно справляются с задачами выявления проблем и улучшения процессов разработки. Анализ временных рядов является более эффективным методом по сравнению с традиционными подходами, так как он учитывает динамику изменений и позволяет выявлять закономерности, недоступные при статическом анализе. Существующие инструменты, такие как SonarQube, CodeClimate и GitPrime, предоставляют ценные возможности для анализа качества кода и производительности команды, но ограничены в своих функциях по сравнению с TOM. TOM выделяется благодаря интеграции анализа временных рядов и машинного обучения для предоставления корректирующих действий.
Однако для повышения своей полезности TOM может быть дополнен следующими функциями:
Визуализация процессов: Отображение динамики изменений для наглядного анализа.
Расширенная аналитика: Добавление долгосрочных трендов и отчётов для стратегического управления проектами.
Таким образом, TOM представляет собой перспективный инструмент, который с учётом доработок сможет удовлетворить потребности как разработчиков, так и менеджеров проектов, предоставляя комплексный подход к анализу и улучшению процессов разработки.
